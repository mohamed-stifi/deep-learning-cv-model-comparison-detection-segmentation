{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- dataset: **PASCAL VOC 12**\n",
        "- Metrics: **Pixel Accuracy (PA)**, **Mean Pixel Accuracy (MPA)**, **Intersection over Union (IoU)**, **Mean Intersection over Union (MIoU)**\n",
        "- Models: **context-based methods** DeepLabV3, HRNet\n",
        "- Optimaizers: **Adam**, **AdaGrad**, **RmsProp**"
      ],
      "metadata": {
        "id": "yJrcShIEeb_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import VOCSegmentation\n",
        "from torchvision.models.segmentation import deeplabv3_resnet101\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    'data_root': './data',\n",
        "    'batch_size': 2,\n",
        "    'num_epochs': 10,\n",
        "    'learning_rate': 0.001,\n",
        "    'num_classes': 21,  # PASCAL VOC has 20 classes + background\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'save_dir': './checkpoints',\n",
        "    'results_dir': './results'\n",
        "}\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(CONFIG['save_dir'], exist_ok=True)\n",
        "os.makedirs(CONFIG['results_dir'], exist_ok=True)"
      ],
      "metadata": {
        "id": "9yz3dzsgefPS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data preprocessing and exploration**"
      ],
      "metadata": {
        "id": "TkDllTYFejEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define transformations\n"
      ],
      "metadata": {
        "id": "tb12c2Noel-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    target_transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.NEAREST),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform, target_transform\n",
        "train_transform, val_transform, target_transform=get_transforms()"
      ],
      "metadata": {
        "id": "9T1vUxeSeop0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading"
      ],
      "metadata": {
        "id": "TTXtizXHer0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    train_transform, val_transform, target_transform = get_transforms()\n",
        "\n",
        "    train_dataset = VOCSegmentation(\n",
        "        root=CONFIG['data_root'],\n",
        "        year='2012',\n",
        "        image_set='train',\n",
        "        transform=train_transform,\n",
        "        target_transform=target_transform,\n",
        "        download=True\n",
        "    )\n",
        "\n",
        "    val_dataset = VOCSegmentation(\n",
        "        root=CONFIG['data_root'],\n",
        "        year='2012',\n",
        "        image_set='val',\n",
        "        transform=val_transform,\n",
        "        target_transform=target_transform,\n",
        "        download=True\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=CONFIG['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=CONFIG['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "train_loader, val_loader=load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ6-DQZBeu5V",
        "outputId": "907782ec-9a1d-4de7-a5d3-8c009e7a3696"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.00G/2.00G [01:26<00:00, 23.1MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data exploration"
      ],
      "metadata": {
        "id": "11lI0JpGeyOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_data(train_loader):\n",
        "    print(\"Data Exploration:\")\n",
        "\n",
        "    # Get a batch\n",
        "    images, masks = next(iter(train_loader))\n",
        "\n",
        "    # Print shapes\n",
        "    print(f\"Image batch shape: {images.shape}\")\n",
        "    print(f\"Mask batch shape: {masks.shape}\")\n",
        "\n",
        "    # Visualize some samples\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    for i in range(min(4, CONFIG['batch_size'])):\n",
        "        # Display image\n",
        "        plt.subplot(2, 4, i+1)\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img = np.clip(img, 0, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Display mask\n",
        "        plt.subplot(2, 4, i+5)\n",
        "        mask = masks[i].squeeze().numpy()\n",
        "        plt.imshow(mask)\n",
        "        plt.title(f\"Mask {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG['results_dir'], 'data_samples.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Class distribution\n",
        "    class_counts = {}\n",
        "    for _, mask in tqdm(train_loader, desc=\"Analyzing class distribution\"):\n",
        "        for class_id in range(CONFIG['num_classes']):\n",
        "            pixels = (mask == class_id).sum().item()\n",
        "            if class_id in class_counts:\n",
        "                class_counts[class_id] += pixels\n",
        "            else:\n",
        "                class_counts[class_id] = pixels\n",
        "\n",
        "    # Plot class distribution\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(class_counts.keys(), class_counts.values())\n",
        "    plt.xlabel('Class ID')\n",
        "    plt.ylabel('Pixel Count')\n",
        "    plt.title('Class Distribution in PASCAL VOC 2012')\n",
        "    plt.savefig(os.path.join(CONFIG['results_dir'], 'class_distribution.png'))\n",
        "    plt.close()\n",
        "\n",
        "    print(\"Data exploration completed. Visualization saved.\")\n",
        "    return class_counts\n",
        "class_counts=explore_data(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkvN8atwe0cj",
        "outputId": "60e663f3-0150-4a89-86fc-773beb173774"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Exploration:\n",
            "Image batch shape: torch.Size([2, 3, 256, 256])\n",
            "Mask batch shape: torch.Size([2, 1, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing class distribution: 100%|██████████| 732/732 [00:14<00:00, 49.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exploration completed. Visualization saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementation of Models**"
      ],
      "metadata": {
        "id": "HDVPDnare3xE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models & optimizers definition"
      ],
      "metadata": {
        "id": "fSQLY5EKe8Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_deeplabv3():\n",
        "    model = deeplabv3_resnet101(pretrained=True)\n",
        "    model.classifier[4] = nn.Conv2d(256, CONFIG['num_classes'], kernel_size=1)\n",
        "    return model\n",
        "\n",
        "class HRNet(nn.Module):\n",
        "    def __init__(self, num_classes=21):\n",
        "        super(HRNet, self).__init__()\n",
        "        # We'll use a simplified HRNet implementation\n",
        "        # Initialize with a pretrained backbone (ResNet in this case)\n",
        "        backbone = torchvision.models.resnet50(pretrained=True)\n",
        "        self.layer0 = nn.Sequential(\n",
        "            backbone.conv1,\n",
        "            backbone.bn1,\n",
        "            backbone.relu,\n",
        "            backbone.maxpool\n",
        "        )\n",
        "        self.layer1 = backbone.layer1\n",
        "        self.layer2 = backbone.layer2\n",
        "        self.layer3 = backbone.layer3\n",
        "        self.layer4 = backbone.layer4\n",
        "\n",
        "        # High-resolution branches\n",
        "        self.high_res_branch = nn.Sequential(\n",
        "            nn.Conv2d(2048, 512, kernel_size=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Final classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, num_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.high_res_branch(x)\n",
        "        x = F.interpolate(x, scale_factor=16, mode='bilinear', align_corners=True)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return {'out': x}\n",
        "\n",
        "def get_model(model_name):\n",
        "    if model_name.lower() == 'deeplabv3':\n",
        "        return get_deeplabv3()\n",
        "    elif model_name.lower() == 'hrnet':\n",
        "        return HRNet(CONFIG['num_classes'])\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model_name} not supported!\")\n",
        "\n",
        "def get_optimizer(model, optimizer_name, lr=0.001):\n",
        "    if optimizer_name.lower() == 'adam':\n",
        "        return optim.Adam(model.parameters(), lr=lr)\n",
        "    elif optimizer_name.lower() == 'adagrad':\n",
        "        return optim.Adagrad(model.parameters(), lr=lr)\n",
        "    elif optimizer_name.lower() == 'rmsprop':\n",
        "        return optim.RMSprop(model.parameters(), lr=lr)\n",
        "    else:\n",
        "        raise ValueError(f\"Optimizer {optimizer_name} not supported!\")"
      ],
      "metadata": {
        "id": "UDQh1iGfe-Td"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate gradients statistics"
      ],
      "metadata": {
        "id": "oTLGAHSrfDrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gradient_stats(model):\n",
        "    grad_stats = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.grad is not None:\n",
        "            grad_stats[name] = {\n",
        "                'mean': param.grad.mean().item(),\n",
        "                'std': param.grad.std().item(),\n",
        "                'min': param.grad.min().item(),\n",
        "                'max': param.grad.max().item()\n",
        "            }\n",
        "    return grad_stats"
      ],
      "metadata": {
        "id": "pIBTyXybfFl5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop"
      ],
      "metadata": {
        "id": "NbGuiij0fIjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    gradient_stats = []\n",
        "\n",
        "    with tqdm(train_loader, desc=\"Training\") as pbar:\n",
        "        for images, masks in pbar:\n",
        "            images = images.to(device)\n",
        "            masks = masks.long().squeeze(1).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)['out']\n",
        "\n",
        "            # Resize masks to match output size\n",
        "            if outputs.shape[2:] != masks.shape[1:]:\n",
        "                masks = F.interpolate(masks.unsqueeze(1).float(), size=outputs.shape[2:],\n",
        "                                      mode='nearest').squeeze(1).long()\n",
        "\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            # Rest of the function remains the same\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Collect gradient statistics\n",
        "            grad_stats = get_gradient_stats(model)\n",
        "            gradient_stats.append(grad_stats)\n",
        "\n",
        "            # Update stats\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': running_loss / (pbar.n + 1)})\n",
        "\n",
        "    return running_loss / len(train_loader), gradient_stats\n"
      ],
      "metadata": {
        "id": "hblP6hU_fLPd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation metrics"
      ],
      "metadata": {
        "id": "NlpkWMn3fQoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(pred, target, num_classes=21):\n",
        "    # Convert tensors to numpy arrays\n",
        "    pred = pred.cpu().numpy()\n",
        "    target = target.cpu().numpy()\n",
        "\n",
        "    # Initialize metrics\n",
        "    pixel_accuracy = 0.0\n",
        "    class_accuracy = np.zeros(num_classes)\n",
        "    iou = np.zeros(num_classes)\n",
        "\n",
        "    # Calculate metrics for each image\n",
        "    for i in range(pred.shape[0]):\n",
        "        # Pixel Accuracy\n",
        "        pixel_accuracy += np.mean(pred[i] == target[i])\n",
        "\n",
        "        # Class Accuracy and IoU\n",
        "        for cls in range(num_classes):\n",
        "            pred_cls = pred[i] == cls\n",
        "            target_cls = target[i] == cls\n",
        "\n",
        "            # Skip if class not present in ground truth\n",
        "            if np.sum(target_cls) == 0:\n",
        "                continue\n",
        "\n",
        "            # Class accuracy\n",
        "            class_accuracy[cls] += np.sum(pred_cls & target_cls) / np.sum(target_cls)\n",
        "\n",
        "            # IoU\n",
        "            intersection = np.sum(pred_cls & target_cls)\n",
        "            union = np.sum(pred_cls | target_cls)\n",
        "\n",
        "            if union > 0:\n",
        "                iou[cls] += intersection / union\n",
        "\n",
        "    # Normalize by batch size\n",
        "    pixel_accuracy /= pred.shape[0]\n",
        "\n",
        "    # Count classes present in the batch\n",
        "    class_counts = np.zeros(num_classes)\n",
        "    for i in range(pred.shape[0]):\n",
        "        for cls in range(num_classes):\n",
        "            if np.sum(target[i] == cls) > 0:\n",
        "                class_counts[cls] += 1\n",
        "\n",
        "    # Normalize by class counts\n",
        "    for cls in range(num_classes):\n",
        "        if class_counts[cls] > 0:\n",
        "            class_accuracy[cls] /= class_counts[cls]\n",
        "            iou[cls] /= class_counts[cls]\n",
        "\n",
        "    # Mean metrics\n",
        "    mean_pixel_accuracy = np.mean([class_accuracy[c] for c in range(num_classes) if class_counts[c] > 0])\n",
        "    mean_iou = np.mean([iou[c] for c in range(num_classes) if class_counts[c] > 0])\n",
        "\n",
        "    metrics = {\n",
        "        'PA': pixel_accuracy,\n",
        "        'MPA': mean_pixel_accuracy,\n",
        "        'IoU': iou,\n",
        "        'MIoU': mean_iou\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "mwukR5zKfRKM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation loop"
      ],
      "metadata": {
        "id": "ktBnpyWwfWs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_metrics = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with tqdm(val_loader, desc=\"Validation\") as pbar:\n",
        "            for images, masks in pbar:\n",
        "                images = images.to(device)\n",
        "                masks = masks.long().squeeze(1).to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)['out']\n",
        "\n",
        "                # Resize masks to match output size\n",
        "                if outputs.shape[2:] != masks.shape[1:]:\n",
        "                    masks = F.interpolate(masks.unsqueeze(1).float(), size=outputs.shape[2:],\n",
        "                                          mode='nearest').squeeze(1).long()\n",
        "\n",
        "                loss = criterion(outputs, masks)\n",
        "\n",
        "                # Get predictions\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                # Calculate metrics\n",
        "                metrics = calculate_metrics(preds, masks, CONFIG['num_classes'])\n",
        "                all_metrics.append(metrics)\n",
        "\n",
        "                # Update stats\n",
        "                running_loss += loss.item()\n",
        "                pbar.set_postfix({'loss': running_loss / (pbar.n + 1), 'MIoU': metrics['MIoU']})\n",
        "\n",
        "    # Aggregate metrics\n",
        "    agg_metrics = {\n",
        "        'PA': np.mean([m['PA'] for m in all_metrics]),\n",
        "        'MPA': np.mean([m['MPA'] for m in all_metrics]),\n",
        "        'MIoU': np.mean([m['MIoU'] for m in all_metrics]),\n",
        "        'IoU': np.mean([m['IoU'] for m in all_metrics], axis=0)\n",
        "    }\n",
        "\n",
        "    return running_loss / len(val_loader), agg_metrics"
      ],
      "metadata": {
        "id": "WvFbR27ufXZ2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize predictions"
      ],
      "metadata": {
        "id": "8HmgX5ZmfakH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, val_loader, device, num_samples=4):\n",
        "    model.eval()\n",
        "    images, masks = next(iter(val_loader))\n",
        "    images = images.to(device)\n",
        "    masks = masks.squeeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)['out']\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Create a colormap\n",
        "    cmap = plt.cm.get_cmap('tab20', CONFIG['num_classes'])\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    for i in range(min(num_samples, images.shape[0])):\n",
        "        # Original image\n",
        "        plt.subplot(3, num_samples, i+1)\n",
        "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img = np.clip(img, 0, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ground truth\n",
        "        plt.subplot(3, num_samples, i+num_samples+1)\n",
        "        plt.imshow(masks[i].cpu().numpy(), cmap=cmap, vmin=0, vmax=CONFIG['num_classes']-1)\n",
        "        plt.title(f\"Ground Truth {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Prediction\n",
        "        plt.subplot(3, num_samples, i+2*num_samples+1)\n",
        "        plt.imshow(preds[i].cpu().numpy(), cmap=cmap, vmin=0, vmax=CONFIG['num_classes']-1)\n",
        "        plt.title(f\"Prediction {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG['results_dir'], 'predictions.png'))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "SMf-3tvrfdKD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient analysis visualization"
      ],
      "metadata": {
        "id": "ZeoRHYOnfgUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_gradients(gradient_stats, optimizer_name):\n",
        "    # Extract data\n",
        "    all_layers = list(gradient_stats[0].keys())\n",
        "    selected_layers = all_layers[:3] + all_layers[-3:]  # First 3 and last 3 layers\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    epochs = range(1, len(gradient_stats) + 1)\n",
        "\n",
        "    # Plot gradient statistics over epochs\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, layer in enumerate(selected_layers):\n",
        "        mean_values = [stats[layer]['mean'] for stats in gradient_stats]\n",
        "        std_values = [stats[layer]['std'] for stats in gradient_stats]\n",
        "\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.plot(epochs, mean_values, 'b-', label='Mean')\n",
        "        plt.fill_between(epochs,\n",
        "                         [m - s for m, s in zip(mean_values, std_values)],\n",
        "                         [m + s for m, s in zip(mean_values, std_values)],\n",
        "                         alpha=0.3)\n",
        "        plt.title(f'Layer: {layer.split(\".\")[-1]}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Gradient Value')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.suptitle(f'Gradient Analysis - {optimizer_name} Optimizer')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG['results_dir'], f'gradient_analysis_{optimizer_name}.png'))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "IBGn24EBfihL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimentation**"
      ],
      "metadata": {
        "id": "09h9--adfoQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training & evaluation pipeline"
      ],
      "metadata": {
        "id": "OcQPmK_EfrFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model_name, optimizer_name):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Running experiment: Model={model_name}, Optimizer={optimizer_name}\")\n",
        "    print(f\"{'='*50}\\n\")\n",
        "\n",
        "    # Load data\n",
        "    train_loader, val_loader = load_data()\n",
        "\n",
        "    # Create model\n",
        "    model = get_model(model_name)\n",
        "    model = model.to(CONFIG['device'])\n",
        "\n",
        "    # Create optimizer\n",
        "    optimizer = get_optimizer(model, optimizer_name, CONFIG['learning_rate'])\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Initialize trackers\n",
        "    best_miou = 0.0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    metrics_history = []\n",
        "    all_gradient_stats = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(CONFIG['num_epochs']):\n",
        "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, grad_stats = train(model, train_loader, optimizer, criterion, CONFIG['device'])\n",
        "        train_losses.append(train_loss)\n",
        "        all_gradient_stats.append(grad_stats[-1])  # Save the last batch gradient stats\n",
        "\n",
        "        # Validate\n",
        "        val_loss, metrics = validate(model, val_loader, criterion, CONFIG['device'])\n",
        "        val_losses.append(val_loss)\n",
        "        metrics_history.append(metrics)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "        print(f\"PA: {metrics['PA']:.4f}, MPA: {metrics['MPA']:.4f}, MIoU: {metrics['MIoU']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if metrics['MIoU'] > best_miou:\n",
        "            best_miou = metrics['MIoU']\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'metrics': metrics\n",
        "            }, os.path.join(CONFIG['save_dir'], f\"{model_name}_{optimizer_name}_best.pth\"))\n",
        "            print(f\"New best model saved! MIoU: {best_miou:.4f}\")\n",
        "\n",
        "    # Visualize training progress\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss Curves')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot([m['PA'] for m in metrics_history], label='PA')\n",
        "    plt.plot([m['MPA'] for m in metrics_history], label='MPA')\n",
        "    plt.plot([m['MIoU'] for m in metrics_history], label='MIoU')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.title('Performance Metrics')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG['results_dir'], f'{model_name}_{optimizer_name}_training.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Load best model for final evaluation\n",
        "    checkpoint = torch.load(os.path.join(CONFIG['save_dir'], f\"{model_name}_{optimizer_name}_best.pth\"), weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Final validation\n",
        "    _, final_metrics = validate(model, val_loader, criterion, CONFIG['device'])\n",
        "\n",
        "    # Visualize some predictions\n",
        "    visualize_predictions(model, val_loader, CONFIG['device'])\n",
        "\n",
        "    # Visualize gradient analysis\n",
        "    visualize_gradients(all_gradient_stats, optimizer_name)\n",
        "\n",
        "    return final_metrics"
      ],
      "metadata": {
        "id": "LtVTk2CHfpDc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['DeepLabV3', 'HRNet']\n",
        "optimizers = ['Adam', 'AdaGrad', 'RmsProp']\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name in models:\n",
        "        for optimizer_name in optimizers:\n",
        "            metrics = run_experiment(model_name, optimizer_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIl6Zfqhf0Z0",
        "outputId": "30c22f9e-2ab2-4c43-eb2e-efc602497584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: Model=DeepLabV3, Optimizer=Adam\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 167MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:46<00:00,  3.23it/s, loss=0.279]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.58it/s, loss=0.219, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2787, Val Loss: 0.2187\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "New best model saved! MIoU: 0.4724\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:48<00:00,  3.21it/s, loss=0.215]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.53it/s, loss=0.22, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2152, Val Loss: 0.2204\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:50<00:00,  3.17it/s, loss=0.214]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.51it/s, loss=0.224, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2141, Val Loss: 0.2236\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:50<00:00,  3.18it/s, loss=0.214]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.56it/s, loss=0.213, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2144, Val Loss: 0.2130\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:49<00:00,  3.19it/s, loss=0.213]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.50it/s, loss=0.21, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2132, Val Loss: 0.2103\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:50<00:00,  3.18it/s, loss=0.213]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.54it/s, loss=0.211, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2132, Val Loss: 0.2114\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:51<00:00,  3.16it/s, loss=0.213]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.51it/s, loss=0.213, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2126, Val Loss: 0.2133\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:50<00:00,  3.18it/s, loss=0.213]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.50it/s, loss=0.219, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2130, Val Loss: 0.2189\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:50<00:00,  3.18it/s, loss=0.213]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.54it/s, loss=0.225, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2128, Val Loss: 0.2248\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:50<00:00,  3.18it/s, loss=0.213]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.47it/s, loss=0.212, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2128, Val Loss: 0.2113\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.59it/s, loss=0.219, MIoU=0.494]\n",
            "<ipython-input-10-964bfa2a5780>:12: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cmap = plt.cm.get_cmap('tab20', CONFIG['num_classes'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: Model=DeepLabV3, Optimizer=AdaGrad\n",
            "==================================================\n",
            "\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:47<00:00,  3.21it/s, loss=0.579]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.52it/s, loss=0.29, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5787, Val Loss: 0.2898\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "New best model saved! MIoU: 0.4724\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:47<00:00,  3.21it/s, loss=0.257]\n",
            "Validation: 100%|██████████| 725/725 [01:08<00:00, 10.54it/s, loss=0.248, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2575, Val Loss: 0.2475\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "New best model saved! MIoU: 0.4724\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:47<00:00,  3.21it/s, loss=0.233]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.47it/s, loss=0.23, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2328, Val Loss: 0.2293\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:47<00:00,  3.21it/s, loss=0.223]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.49it/s, loss=0.217, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2235, Val Loss: 0.2163\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:48<00:00,  3.21it/s, loss=0.219]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.47it/s, loss=0.217, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2195, Val Loss: 0.2163\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:48<00:00,  3.20it/s, loss=0.216]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.46it/s, loss=0.211, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2160, Val Loss: 0.2103\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 732/732 [03:48<00:00,  3.20it/s, loss=0.214]\n",
            "Validation: 100%|██████████| 725/725 [01:09<00:00, 10.47it/s, loss=0.21, MIoU=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2136, Val Loss: 0.2100\n",
            "PA: 0.9447, MPA: 0.5000, MIoU: 0.4724\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  15%|█▌        | 112/732 [00:35<03:10,  3.26it/s, loss=0.227]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation of model performance**"
      ],
      "metadata": {
        "id": "OK7wIzEsf4WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in models:\n",
        "        for optimizer_name in optimizers:\n",
        "            results.append({\n",
        "                'Model': model_name,\n",
        "                'Optimizer': optimizer_name,\n",
        "                'PA': metrics['PA'],\n",
        "                'MPA': metrics['MPA'],\n",
        "                'MIoU': metrics['MIoU']\n",
        "            })\n",
        "            import gc\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-QlVSKG8f7zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparison of results and discussion**"
      ],
      "metadata": {
        "id": "MfyNu6eqf5Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_experiments(results):\n",
        "    # Create comparison dataframe\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Plot comparison\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # PA comparison\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.barplot(x='Model', y='PA', hue='Optimizer', data=df)\n",
        "    plt.title('Pixel Accuracy Comparison')\n",
        "\n",
        "    # MPA comparison\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sns.barplot(x='Model', y='MPA', hue='Optimizer', data=df)\n",
        "    plt.title('Mean Pixel Accuracy Comparison')\n",
        "\n",
        "    # MIoU comparison\n",
        "    plt.subplot(2, 2, 3)\n",
        "    sns.barplot(x='Model', y='MIoU', hue='Optimizer', data=df)\n",
        "    plt.title('Mean IoU Comparison')\n",
        "\n",
        "    # Best model-optimizer combination\n",
        "    plt.subplot(2, 2, 4)\n",
        "    best_idx = df['MIoU'].idxmax()\n",
        "    best_model = df.loc[best_idx, 'Model']\n",
        "    best_optim = df.loc[best_idx, 'Optimizer']\n",
        "\n",
        "    plt.text(0.5, 0.5, f\"Best Model: {best_model}\\nBest Optimizer: {best_optim}\\nMIoU: {df.loc[best_idx, 'MIoU']:.4f}\",\n",
        "             ha='center', va='center', fontsize=14)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG['results_dir'], 'model_optimizer_comparison.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Save results to CSV\n",
        "    df.to_csv(os.path.join(CONFIG['results_dir'], 'experiment_results.csv'), index=False)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "YKkhxnMYgBJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison = compare_experiments(results)\n",
        "print(\"\\nExperiment Results:\")\n",
        "print(comparison)\n",
        "\n",
        "print(f\"\\nAll experiments completed! Results saved to {CONFIG['results_dir']}\")"
      ],
      "metadata": {
        "id": "o2HZBFSrgOOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
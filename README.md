---

# **deep-learning-cv-model-comparison-detection-segmentation**

### ðŸ“Š Comparative analysis of deep learning models for object detection, semantic segmentation, and instance segmentation using PASCAL VOC and Penn-Fudan datasets.

---

## ðŸ“Œ Overview

This project presents a comparative study of state-of-the-art deep learning models across three core computer vision tasks:

- **Object Detection**
- **Semantic Segmentation**
- **Instance Segmentation**

We evaluate models on performance, training dynamics, and optimizer effectiveness using standard datasets and metrics.

---

## ðŸ§  Objectives

- Evaluate and compare multiple deep learning models on different vision tasks.
- Understand the impact of optimizers (Adam, AdaGrad, RMSprop) on convergence and gradient stability.
- Use quantitative metrics (mAP, IoU, pixel accuracy, etc.) for model assessment.
- Visualize training behavior, gradient flow, and detection/segmentation outcomes.

---

## ðŸ—‚ï¸ Project Structure

```
deep-learning-cv-model-comparison-detection-segmentation/
â”‚
â”œâ”€â”€ Notebooks
|    â”‚
|    â”œâ”€â”€ Object detection/object detection.ipynb                   # Object detection with Faster R-CNN and SSD
|    â”œâ”€â”€ Instance segmentation/instance segmenatation.ipynb        # Instance segmentation with Mask R-CNN and Panoptic FPN
|    â””â”€â”€ Semantic segmentation/semantic segmentation.ipynb         # Semantic segmentation  
|
â””â”€â”€ README.md                          # Project documentation
```

---

## ðŸ“š Tasks & Models

### **1. Object Detection**
- ðŸ“¦ **Dataset**: PASCAL VOC 2012
- ðŸ§  **Models**:
  - Faster R-CNN (Two-stage)
  - SSD / YOLO (Single-stage)
- ðŸ“ **Metrics**: Precision, Recall, mAP (mean Average Precision)

---

### **2. Semantic Segmentation**
- ðŸ“¦ **Dataset**: PASCAL VOC 2012 (segmentation annotations)
- ðŸ§  **Models**:
  - DeepLabV3 (ResNet-101 backbone)
  - HRNet
- ðŸ“ **Metrics**:
  - Pixel Accuracy (PA)
  - Mean Pixel Accuracy (MPA)
  - Mean Intersection over Union (mIoU)

---

### **3. Instance Segmentation**
- ðŸ“¦ **Dataset**: Penn-Fudan Pedestrian
- ðŸ§  **Models**:
  - Mask R-CNN (Two-stage)
  - Panoptic FPN (Single-stage)
- ðŸ“ **Metrics**:
  - mIoU
  - Precision
  - Recall
  - mAP

---

## âš™ï¸ Optimization Strategies

We compare three widely-used optimizers across all models:

- **Adam** (most stable across experiments)
- **AdaGrad**
- **RMSprop**

Gradient behavior, learning rates, and training stability were analyzed and visualized for each optimizer.

---

## ðŸ“Š Results Summary

| Task | Best Model | Best Optimizer | Highlight |
|------|------------|----------------|-----------|
| Object Detection | Faster R-CNN | Adam | Highest mAP |
| Semantic Segmentation | DeepLabV3 | Adam | Robust mIoU |
| Instance Segmentation | Mask R-CNN | Adam | Smooth convergence |

> Note: Panoptic FPN suffered from metric logging issues that need debugging.

---

## ðŸ“· Visual Outputs

- ðŸ“ˆ Loss and gradient plots per epoch
- ðŸ“‰ Learning rate vs. performance trends
- ðŸŽ¯ Detection bounding boxes and segmentation masks (ground truth vs prediction)
- ðŸ“Š Metric heatmaps and optimizer comparisons

All results are saved in the `results/` folder.

---

## ðŸš€ Getting Started

### ðŸ“¦ Requirements
- Python 3.8+
- PyTorch
- TorchVision
- NumPy, OpenCV, Matplotlib, Seaborn, etc.



---

## ðŸ Future Work

- Add COCO dataset evaluations
- Extend to panoptic segmentation benchmarking
- Incorporate advanced optimizers (Lookahead, Ranger)
- Experiment with model quantization and pruning

---

## ðŸ“š References

- Ren et al. (2015), *Faster R-CNN*
- Liu et al. (2016), *SSD*
- He et al. (2017), *Mask R-CNN*
- Chen et al. (2017), *DeepLabV3*
- Kirillov et al. (2019), *Panoptic FPN*
- PASCAL VOC, Penn-Fudan datasets

---

## ðŸ‘¨â€ðŸ’» Authors

- **Mohamed STIFI**
- **Ayoub EL ASSIOUI**

> Supervised by **Pr. Hanaa EL AFIA** â€“ ENSIAS, Rabat

---
